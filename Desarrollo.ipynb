{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes:\\\n",
    "    Christopher Gilbert \\\n",
    "    Manuel Sandoval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas:\n",
    "* [a](#a)\n",
    "* [b](#b)\n",
    "* [c](#c)\n",
    "* [d](#d)\n",
    "* [e](#e)\n",
    "* [f](#f)\n",
    "* [g](#g)\n",
    "* [h](#h)\n",
    "* [i](#i)\n",
    "* [j](#j)\n",
    "* [k](#k)\n",
    "* [l](#l)\n",
    "* [m](#m)\n",
    "* [n](#n)\n",
    "* [o](#o)\n",
    "* [p](#p)\n",
    "* [q](#p)\n",
    "* [r](#p)\n",
    "* [s](#s)\n",
    "* [t](#t)\n",
    "* [u](#u)\n",
    "* [v](#v)\n",
    "* [Actividad 2](#Actividad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datos y separacion test-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ftr = open(\"train_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "df_train = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "df_train['Sentiment'] = (pd.to_numeric(df_train['Sentiment'])+1)/2 # 0 o 1\n",
    "\n",
    "fts = open(\"test_data.csv\", \"r\",  encoding=\"ISO-8859-1\")\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "df_test = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "df_test['Sentiment'] = (pd.to_numeric(df_test['Sentiment'])+1)/2 # 0 o 1\n",
    "\n",
    "df_train_text = df_train.Text\n",
    "df_test_text = df_test.Text\n",
    "labels_train = df_train.Sentiment.values\n",
    "labels_test = df_test.Sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)<a class=\"anchor\" id=\"a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describir datos trabajados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3554 entries, 0 to 3553\n",
      "Data columns (total 2 columns):\n",
      "Sentiment    3554 non-null float64\n",
      "Text         3554 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 55.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>everything's serious , poetic , earnest and --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>narratively , trouble every day is a plodding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a truly wonderful tale combined with stunning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jason patric and ray liotta make for one splen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>haneke keeps us at arm's length . guided more ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0        0.0  everything's serious , poetic , earnest and --...\n",
       "1        0.0  narratively , trouble every day is a plodding ...\n",
       "2        1.0  a truly wonderful tale combined with stunning ...\n",
       "3        1.0  jason patric and ray liotta make for one splen...\n",
       "4        0.0  haneke keeps us at arm's length . guided more ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma = 0\n",
    "i = 0\n",
    "for sentence in df_train['Text']:\n",
    "    if i == 0:\n",
    "        minimo = len(sentence)\n",
    "        maximo = len(sentence)\n",
    "    else:\n",
    "        if minimo>len(sentence):\n",
    "            minimo = len(sentence)\n",
    "            min_sent = sentence\n",
    "        if maximo<len(sentence):\n",
    "            maximo = len(sentence)\n",
    "            max_sent = sentence\n",
    "    i+=1\n",
    "    suma += len(sentence)\n",
    "avg_len = suma/len(df_train['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114.70709060213844, 7, 267, 'crummy\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(avg_len, minimo, maximo, min_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>screenwriter dan schneider and director shawn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home alone goes hollywood , a funny premise un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>seldom has a movie so closely matched the spir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>less dizzying than just dizzy , the jaunt is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an ultra-low-budget indie debut that smacks mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0        0.0  screenwriter dan schneider and director shawn ...\n",
       "1        0.0  home alone goes hollywood , a funny premise un...\n",
       "2        1.0  seldom has a movie so closely matched the spir...\n",
       "3        0.0  less dizzying than just dizzy , the jaunt is p...\n",
       "4        0.0  an ultra-low-budget indie debut that smacks mo..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma = 0\n",
    "i = 0\n",
    "for sentence in df_test['Text']:\n",
    "    if i == 0:\n",
    "        minimo = len(sentence)\n",
    "        maximo = len(sentence)\n",
    "    else:\n",
    "        if minimo>len(sentence):\n",
    "            minimo = len(sentence)\n",
    "            min_sent = sentence\n",
    "        if maximo<len(sentence):\n",
    "            maximo = len(sentence)\n",
    "            max_sent = sentence\n",
    "    i+=1\n",
    "    suma += len(sentence)\n",
    "avg_len = suma/len(df_train['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116.4679234665166, 9, 268, 'horrible\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(avg_len, minimo, maximo, min_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un mejor analisis preliminar seria de utilidad la eliminacion de las stopwords a la hora de poder determinar los largos maximo, minimo y el promedio del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "           Text\n",
      "Sentiment      \n",
      "0.0        1784\n",
      "1.0        1770\n",
      "Train:\n",
      "           Text\n",
      "Sentiment      \n",
      "0.0        1803\n",
      "1.0        1751\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(df_train.groupby(['Sentiment']).count())\n",
    "print(\"Train:\")\n",
    "print(df_test.groupby(['Sentiment']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que en ambos datasets que existe una cantidad balanceada de registros por cada label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)<a class=\"anchor\" id=\"b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train_text, df_val_text, labels_train, labels_val  = train_test_split(df_train, labels_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2843, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)<a class=\"anchor\" id=\"c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "def word_extractor(text):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #delete stopwords\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "... #try yourself\n",
    "word_extractor(\"I love to eat cake\")\n",
    "word_extractor(\"I love eating cake\")\n",
    "word_extractor(\"I loved eating the cake\")\n",
    "word_extractor(\"I do not love eating cake\")\n",
    "word_extractor(\"I don't love eating cake\")\n",
    "... #try yourself\n",
    "texts_train = [word_extractor(text[1]) for text in df_train_text.to_numpy()]\n",
    "texts_val = [word_extractor(text[1]) for text in df_val_text.to_numpy()]\n",
    "texts_test = [word_extractor(text[1]) for text in df_test.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La importancia del preprocesamiento en el dominio del lenguaje natural radica en disminuir las palabras que si bien aparecen con mas frecuencia son las menos significantes para realizar analisis (las stopwords) para asi reducir ruido y tiempo de ejecucion. Tambien es importante el proceso de reducir las palabras a su origen con stemming o lematizacion para evitar analizar palabras cuya semantica es identica pero estan escritas diferentes producto de una conjugacion. En este caso se utiliza lematizacion ya que presenta mejores resultados que stemming al realizar el proceso considerando el contexto en el cual se encuentra la palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)<a class=\"anchor\" id=\"d\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representacion TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2894</td>\n",
       "      <td>film</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4954</td>\n",
       "      <td>movie</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5245</td>\n",
       "      <td>one</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3422</td>\n",
       "      <td>ha</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4434</td>\n",
       "      <td>like</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4607</td>\n",
       "      <td>make</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>story</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>character</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2603</td>\n",
       "      <td>even</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7649</td>\n",
       "      <td>time</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  frec\n",
       "2894       film   468\n",
       "4954      movie   399\n",
       "5245        one   208\n",
       "3422         ha   200\n",
       "4434       like   192\n",
       "4607       make   156\n",
       "7200      story   143\n",
       "1200  character   136\n",
       "2603       even   119\n",
       "7649       time   118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary=False) #TF representation\n",
    "vectorizer.fit(texts_train)\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "... #transform val and test\n",
    "\n",
    "\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer2.fit(texts_val)\n",
    "features_val = vectorizer.transform(texts_val)\n",
    "\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer3.fit(texts_test)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "vocab2 = vectorizer.get_feature_names()\n",
    "dist2=list(np.array(features_val.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "vocab3 = vectorizer.get_feature_names()\n",
    "dist3=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "most_common = pd.DataFrame({'word':vocab, 'frec': dist})\n",
    "most_common.sort_values('frec', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia que las palabras mas repetidas corresponden a las mas relacionadas al contexto de los comentarios, que viene siendo peliculas. Dentro del top 10 al menos no se aprecian palabras con alguna polaridad positiva o negativa excepto quizas \"like\", pero esta puede significar tanto \"gustar\" como tambien ser usada en un contexto comparativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)<a class=\"anchor\" id=\"e\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "for s in labels_train:\n",
    "    if s == 1:\n",
    "        sentiment.append(\"Positivo\")\n",
    "    else:\n",
    "        sentiment.append(\"Negativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD #aka LSA\n",
    "import matplotlib.pyplot as plt\n",
    "model = TruncatedSVD(n_components=2)\n",
    "model.fit(features_train)\n",
    "x_plot = model.transform(features_train)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x_plot[:,0], x_plot[:,1], c=labels_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1786], dtype=int64), array([0], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x_plot == x_plot.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.950106  , 1.75240192])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_plot[1786]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positivo'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[1786]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amarillo Positivo, Morado Negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las agrupaciones que se forman parecen contener una cantidad equitativa de positivo y negativo. Estas agrupaciones corresponden a las tematicas de las distintas criticas, pudiendo ser que cada agrupacion sea una pelicula distinta o que hablen sobre caracteristicas de las peliculas como la musica, los actores, etc. Estas agrupaciones se forman a partir de las palabras que componen las oraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f)<a class=\"anchor\" id=\"f\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  0.0001\n",
      "Param C=  0.001\n",
      "Param C=  0.01\n",
      "Param C=  0.1\n",
      "Param C=  1.0\n",
      "Param C=  10.0\n",
      "Param C=  100.0\n",
      "Param C=  1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "def do_LOGIT(x,y,xv,yv, param):\n",
    "    print(\"Param C= \",param)\n",
    "    model= LogisticRegression(penalty = 'l2')\n",
    "    model.set_params(C=param)\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "#Cs = [10**i for i in np.arange(-4,4)]\n",
    "Cs = np.power(np.repeat(10., 8),np.arange(-4,4))\n",
    "def interact_doLOGIT(Css):\n",
    "    train_list =[]\n",
    "    test_list=[]\n",
    "    values=np.log10(Css)\n",
    "    for p in Css:\n",
    "        model, train_acc, test_acc = do_LOGIT(features_train,labels_train,features_val,labels_val, param= p )\n",
    "        train_list.append(train_acc)\n",
    "        test_list.append(test_acc)\n",
    "        #print(train_list)\n",
    "        #print(test_list)\n",
    "     \n",
    "    #print(\"train acc: \",train_acc)\n",
    "    #print(\"val acc: \",test_acc)\n",
    "    plt.figure(figsize = (16,9))\n",
    "    plt.xlabel('Potencia de 10 para C')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(values, train_list, label= \"train\")\n",
    "    plt.scatter(values, test_list, label = \"val\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "#     #Train\n",
    "#     lista_train = model.predict(features_train)\n",
    "#     #\n",
    "#     y_true_train = list(map(str,lista_train))\n",
    "#     y_pred_train = list(map(str,labels_train))\n",
    "#     data = confusion_matrix(y_true_train, y_pred_train)\n",
    "#     df_cm = pd.DataFrame(data, columns=np.unique(y_true_train), index = np.unique(y_true_train))\n",
    "#     df_cm.index.name = 'Actual'\n",
    "#     df_cm.columns.name = 'Predicted Train'\n",
    "#     plt.figure(figsize = (10,7))\n",
    "#     sn.set(font_scale=1.2)#for label size\n",
    "#     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "    \n",
    "#     #Val\n",
    "#     lista_val = model.predict(features_val)\n",
    "#     #\n",
    "#     y_true_val = list(map(str,lista_val))\n",
    "#     y_pred_val = list(map(str,labels_val))\n",
    "#     data = confusion_matrix(y_true_val, y_pred_val)\n",
    "#     df_cm = pd.DataFrame(data, columns=np.unique(y_true_val), index = np.unique(y_true_val))\n",
    "#     df_cm.index.name = 'Actual'\n",
    "#     df_cm.columns.name = 'Predicted Val'\n",
    "#     plt.figure(figsize = (10,7))\n",
    "#     sn.set(font_scale=1.2)#for label size\n",
    "#     sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "    \n",
    "# interact(interact_doLOGIT, Css=Cs)\n",
    "interact_doLOGIT(Cs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible apreciar que el mejor valor de accuracy para el training set se obtiene con un C > 1 ya que se obtiene un 100%. Por otro lado, el mejor accuracy que se obtiene en el validation set corresponde a uno superior a 70%, posiblemente 71% el cual se logra con un C = 1 y que al aumentar produce una disminucion en el accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g)<a class=\"anchor\" id=\"g\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  0.0001 Kernel=  linear\n",
      "Param C=  0.001 Kernel=  linear\n",
      "Param C=  0.01 Kernel=  linear\n",
      "Param C=  0.1 Kernel=  linear\n",
      "Param C=  1.0 Kernel=  linear\n",
      "Param C=  10.0 Kernel=  linear\n",
      "Param C=  100.0 Kernel=  linear\n",
      "Param C=  1000.0 Kernel=  linear\n",
      "Param C=  0.0001 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  0.001 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  0.01 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  0.1 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  1.0 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  10.0 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  100.0 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  1000.0 Kernel=  rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "def do_SVM(x,y,xv,yv, param, kernel='linear'):\n",
    "    C = param\n",
    "    print(\"Param C= \",C, 'Kernel= ', kernel)\n",
    "    model= SVM()\n",
    "    model.set_params(C=C,kernel=kernel) #try rbf and linear at least\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "Cs = np.power(np.repeat(10., 8),np.arange(-4,4))\n",
    "\n",
    "def interact_doSVM(Css, kernels):\n",
    "    values=np.log10(Css)\n",
    "    for kernel in kernels:\n",
    "        train_list =[]\n",
    "        test_list=[]\n",
    "        for Cs in Css:\n",
    "            model, train_acc, test_acc = do_SVM(features_train, labels_train, features_val, labels_val, param= Cs, kernel=kernel)\n",
    "            train_list.append(train_acc)\n",
    "            test_list.append(test_acc)\n",
    "        plt.figure(figsize = (16,9))\n",
    "        plt.xlabel('Potencia de 10 para C')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.scatter(values, train_list, label= \"train\")\n",
    "        plt.scatter(values, test_list, label = \"val\")\n",
    "        plt.title(kernel)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.grid()\n",
    "\n",
    "    #Train\n",
    "    # lista_train = model.predict(features_train)\n",
    "    # #\n",
    "    # y_true_train = list(map(str,lista_train))\n",
    "    # y_pred_train = list(map(str,labels_train))\n",
    "    # data = confusion_matrix(y_true_train, y_pred_train)\n",
    "    # df_cm = pd.DataFrame(data, columns=np.unique(y_true_train), index = np.unique(y_true_train))\n",
    "    # df_cm.index.name = 'Actual'\n",
    "    # df_cm.columns.name = 'Predicted Train'\n",
    "    # plt.figure(figsize = (10,7))\n",
    "    # sn.set(font_scale=1.2)#for label size\n",
    "    # sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "    \n",
    "    # #Val\n",
    "    # lista_val = model.predict(features_val)\n",
    "    # #\n",
    "    # y_true_val = list(map(str,lista_val))\n",
    "    # y_pred_val = list(map(str,labels_val))\n",
    "    # data = confusion_matrix(y_true_val, y_pred_val)\n",
    "    # df_cm = pd.DataFrame(data, columns=np.unique(y_true_val), index = np.unique(y_true_val))\n",
    "    # df_cm.index.name = 'Actual'\n",
    "    # df_cm.columns.name = 'Predicted Val'\n",
    "    # plt.figure(figsize = (10,7))\n",
    "    # sn.set(font_scale=1.2)#for label size\n",
    "    # sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "\n",
    "interact_doSVM(Css=Cs, kernels = ['linear', 'rbf'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con parametro de regularizacion C menor a 0.01 con kernel lineal, la SVM predice que todos los comentarios son negativos. Asi mismo ocurre con al utilizar el kernel rbf solo que para este caso el valor de C no puede ser menor a 10, pero aun con este valor, el accuracy de la SVM solo llega a ser del 50% por lo que es recomendable utilizar un valor mayor. Para el caso del kernel lineal con C igual a 0.01 se obtienen mejores resultados que rbf con 10, pero aun asi mejorables. Al aumentar el valor de C el accuracy para el training set mejora llegando a ser igual a 1 para valores de C > 1 pero para el caso de test set el valor llega a su maximo (69.2%) para C = 0.1 y con valores mayores va descendiendo hasta 68.7% para el caso de kernel linear, pero para rbf el maximo se encuentra con C = 1000 donde en test set alcanza alrededor de 68% de accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h)<a class=\"anchor\" id=\"h\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#k_range = range(1, features_train.shape[0])\n",
    "#scores = []\n",
    "#for k in k_range:\n",
    "#    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "#    knn.fit(features_train, labels_train)\n",
    "#    scores.append(knn.score(features_val, labels_val))\n",
    "#plt.figure(figsize = (16,9))\n",
    "#plt.xlabel('k')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.scatter(k_range, scores)\n",
    "#plt.xticks(np.arange(1, features_train.shape[0], 100)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores.index(max(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo comentado en las 2 celdas anteriores fue utilizado para obtener el valor optimo de vecinos que maximiza el accuracy. Debido al tiempo que demora en ejecutarse es que paso a comentarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param K=  427\n",
      "train acc:  0.6429827646851917\n",
      "val acc:  0.5921237693389592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def do_KNN(x,y,xv,yv, param):\n",
    "    model = KNeighborsClassifier()\n",
    "    print(\"Param K= \",param)\n",
    "    model.set_params(n_neighbors=param)\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "\n",
    "def interact_doKNN(Kss):\n",
    "    model, train_acc, test_acc = do_KNN(features_train, labels_train, features_val, labels_val, param= Kss)\n",
    "    print(\"train acc: \",train_acc)\n",
    "    print(\"val acc: \",test_acc)\n",
    "    \n",
    "    # #Train\n",
    "    # lista_train = model.predict(features_train)\n",
    "    # #\n",
    "    # y_true_train = list(map(str,lista_train))\n",
    "    # y_pred_train = list(map(str,labels_train))\n",
    "    # data = confusion_matrix(y_true_train, y_pred_train)\n",
    "    # df_cm = pd.DataFrame(data, columns=np.unique(y_true_train), index = np.unique(y_true_train))\n",
    "    # df_cm.index.name = 'Actual'\n",
    "    # df_cm.columns.name = 'Predicted Train'\n",
    "    # plt.figure(figsize = (10,7))\n",
    "    # sn.set(font_scale=1.2)#for label size\n",
    "    # sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "    \n",
    "    # #Val\n",
    "    # lista_val = model.predict(features_val)\n",
    "    # #\n",
    "    # y_true_val = list(map(str,lista_val))\n",
    "    # y_pred_val = list(map(str,labels_val))\n",
    "    # data = confusion_matrix(y_true_val, y_pred_val)\n",
    "    # df_cm = pd.DataFrame(data, columns=np.unique(y_true_val), index = np.unique(y_true_val))\n",
    "    # df_cm.index.name = 'Actual'\n",
    "    # df_cm.columns.name = 'Predicted Val'\n",
    "    # plt.figure(figsize = (10,7))\n",
    "    # sn.set(font_scale=1.2)#for label size\n",
    "    # sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})#\n",
    "\n",
    "# Ks = np.arange(1, features_train.shape[0], 10)\n",
    "\n",
    "interact_doKNN(Kss=427)#scores.index(max(scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del valor de k-neighbors utilizados es posible decir que para determinar el sentimiento de una review se necesitan un quinto de los datos que presenten menor disancia (probablemente cosenoidal debido a la dimensionalidad) respecto a la review que se desea predecir para conseguir el mejor accuracy posible en el validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i)<a class=\"anchor\" id=\"i\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b4829f82d94f88a96f7abb61a7d5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Depth', options=(1, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interact_doTree(Depth, Samples)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "def do_Tree(x,y,xv,yv, param_d=None, param_m=2):\n",
    "    model= Tree()\n",
    "    print(\"Param Max-D= \",param_d, 'Min-samples-S= ', param_m)\n",
    "    model.set_params(max_depth=param_d, min_samples_split=param_m) \n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "\n",
    "def interact_doTree(Depth, Samples):\n",
    "    model, train_acc, test_acc = do_Tree(features_train, labels_train, features_val, labels_val, param_d = Depth ,param_m = Samples)\n",
    "    print(\"train acc: \",train_acc)\n",
    "    print(\"val acc: \",test_acc)\n",
    "    \n",
    "    #Train\n",
    "    lista_train = model.predict(features_train)\n",
    "    #\n",
    "    y_true_train = list(map(str,lista_train))\n",
    "    y_pred_train = list(map(str,labels_train))\n",
    "    data = confusion_matrix(y_true_train, y_pred_train)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_true_train), index = np.unique(y_true_train))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted Train'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.2)#for label size\n",
    "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})# font size\n",
    "    \n",
    "    #Val\n",
    "    lista_val = model.predict(features_val)\n",
    "    #\n",
    "    y_true_val = list(map(str,lista_val))\n",
    "    y_pred_val = list(map(str,labels_val))\n",
    "    data = confusion_matrix(y_true_val, y_pred_val)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_true_val), index = np.unique(y_true_val))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted Val'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.2)#for label size\n",
    "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14})#\n",
    "\n",
    "Depths = np.arange(1, features_train.shape[1], 500 ) #choose steps\n",
    "SamplesS = np.arange(2, features_train.shape[0] , 500 ) #choose steps\n",
    "interact(interact_doTree, Depth = Depths, Samples = SamplesS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que al realizar variaciones a la variable Samples el accuracy del arbol disminuye, esto puede ser debido a que al restringir la cantidad de muestras requeridas para seguir subdividiendo los nodos muchas quedan mal clasificadas. Para las opciones presentadas se obtuvo que con un Samples = 2 se obtenia el mejor resultado, pero puede ser que exista un mejor valor que se encuentre entre los valores que se presentan en el dropdown.\n",
    "\n",
    "Por otro lado en la variable Depth, no se observa cambios significativos a la hora de aumentar la profundidad del arbol, aunque es importante destacar que al aumentar el valor se producia una disminucion de la accuracy, como lo fue para Depth = 5501 cuya accuracy era peor que para Depth = 501 en el validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j)<a class=\"anchor\" id=\"j\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-5322aa0d8df2>\", line 1, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 730, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 936, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-5322aa0d8df2>\", line 1, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-5322aa0d8df2>\", line 1, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: must be str, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Program Files\\Python36\\lib\\inspect.py\", line 730, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 936, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-5322aa0d8df2>\", line 1, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: must be str, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2039\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2041\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3341\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3342\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3344\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3345\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2041\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2043\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1385\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1286\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1288\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m             )\n\u001b[0;32m   1290\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "def do_ANN(x,y, xv,yv, param):\n",
    "    print(\"Neuron hidden = \",param)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=param, input_dim=x.shape[1], activation=\"sigmoid\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=SGD(lr=0.1), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x, y, epochs=25, batch_size=128, verbose=0)\n",
    "    train_acc = model.evaluate(x,y, verbose=0)[1] #in position 0 is the loss\n",
    "    test_acc = model.evaluate(xv,yv, verbose=0)[1]\n",
    "    return model, train_acc, test_acc\n",
    "\n",
    "def interact_doANN(paramm):\n",
    "    train_list = []\n",
    "    test_list=[]\n",
    "    for i in paramm:\n",
    "        model, train_acc, test_acc = do_ANN(features_train, labels_train, features_val, labels_val, param = i)\n",
    "        print(\"train acc: \",train_acc)\n",
    "        print(\"val acc: \",test_acc)\n",
    "        train_list.append(train_acc)\n",
    "        test_list.append(test_acc)\n",
    "    plt.figure(figsize = (16,9))\n",
    "    plt.xlabel('Neurons')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(paramm, train_list, label= \"train\")\n",
    "    plt.scatter(paramm, test_list, label = \"val\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "      \n",
    "    \n",
    "N_h = [2**i for i in range(1,10)]\n",
    "neurons = np.asarray(N_h)\n",
    "interact_doANN(N_h)    \n",
    "#interact(interact_doANN, paramm = (2**i for i in range(1,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resultado_NN.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a problemas con Tensorflow este item fue desarrollado en Google Colab y luego se copio el codigo junto al resultado obtenido.\n",
    "\n",
    "Del grafico es posible observar que en el training set la red logra alcanzar como mejor accuracy alrededor de un 73% al utilizar 8 neuronas en la capa oculta y a medida que se iban aumentando el accuracy comenz√≥ a disminuir llegando incluso a 50%, comparable a lanzar una moneda.\n",
    "\n",
    "Por otro lado para el validation set se obtiene que el mayor valor de accuracy tambien se obtiene para 8 neuronas pero este es considerablemente mas bajo que el de training ya que solo llega a casi alcanzar el 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k)<a class=\"anchor\" id=\"k\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejor Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De todos los modelos utilizados el que mejor desempe√±o presento en el conjunto de validacion corresponde al modelo de regresion logistica con parametro de regularizacion \"C\" igual a 1 donde se presenta un accuracy de 71% para el validation set, por lo que se procede a revisar su desempe√±o con el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model, train_acc, test_acc = do_LOGIT(features_train,labels_train,features_val,labels_val, param= 1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146876758581879"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que en el test set tambien se obtiene un valor de accuracy similar al del validation set. Este valor resulta bastante positivo teniendo en cuenta que se esperaba obtener un valor mas bajo que en el caso del validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l)<a class=\"anchor\" id=\"l\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palabras con igual intensidad: 547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6359032076533483"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "def vader_predict(sentences): \n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "    sent_v = []\n",
    "    count = 0 #para contar palabras iguales\n",
    "    for text in sentences:\n",
    "        sentiment_dict = sid_obj.polarity_scores(text) \n",
    "        if sentiment_dict[\"pos\"] > sentiment_dict[\"neg\"]: #based on scores\n",
    "            sent_v.append(1)\n",
    "        else:\n",
    "            if sentiment_dict[\"pos\"] == sentiment_dict[\"neg\"]:\n",
    "                  count = count + 1\n",
    "            sent_v.append(0)\n",
    "    print(\"palabras con igual intensidad: \" + str(count))\n",
    "    return np.asarray(sent_v)\n",
    "vader_pred_test = vader_predict(df_test_text)\n",
    "#vader_pred_test = vader_predict(text_test) #prueba sin stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels_test, vader_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que al utilizar el modelo Vader se obtiene un valor m√°s bajo de accuracy que el obtenido utilizando la regresi√≥n log√≠stica. Esto puede deberse a que en el caso que la intensidad de la frase sea igualmente positiva que negativa, esta es catalogada como negativa por el codigo de la celda anterior, por lo que puede darse el caso que existan frases que deben ser positivas dentro de ese conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m)<a class=\"anchor\" id=\"m\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras pos y neg en Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando en cuenta que el modelo que presento mejor desempe√±o es el de Regresion Logistica, se procedera a seguir utilizando en este apartado dado que es un modelo que realiza predicciones probabilisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '100',\n",
       " '101',\n",
       " '105',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '11th',\n",
       " '13',\n",
       " '13th',\n",
       " '14',\n",
       " '146',\n",
       " '15',\n",
       " '16',\n",
       " '163',\n",
       " '170',\n",
       " '18th',\n",
       " '19',\n",
       " '1915',\n",
       " '1934',\n",
       " '1938',\n",
       " '1940s',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1954',\n",
       " '1955',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960s',\n",
       " '1972',\n",
       " '1975',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1992',\n",
       " '1995',\n",
       " '19th',\n",
       " '20',\n",
       " '2000',\n",
       " '2002',\n",
       " '20th',\n",
       " '21st',\n",
       " '22',\n",
       " '24',\n",
       " '25',\n",
       " '25s',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30s',\n",
       " '37',\n",
       " '3d',\n",
       " '40',\n",
       " '400',\n",
       " '401',\n",
       " '40s',\n",
       " '451',\n",
       " '48',\n",
       " '4ever',\n",
       " '50',\n",
       " '51',\n",
       " '53',\n",
       " '5ths',\n",
       " '60s',\n",
       " '65',\n",
       " '65th',\n",
       " '70s',\n",
       " '71',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '800',\n",
       " '80s',\n",
       " '84',\n",
       " '85',\n",
       " '88',\n",
       " '8th',\n",
       " '90',\n",
       " '90s',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '99',\n",
       " 'aaliyah',\n",
       " 'abandon',\n",
       " 'abandono',\n",
       " 'abbreviated',\n",
       " 'abc',\n",
       " 'abel',\n",
       " 'abhorrent',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'aboul',\n",
       " 'above',\n",
       " 'abrahams',\n",
       " 'abrasive',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'abuse',\n",
       " 'abysmally',\n",
       " 'acabamos',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accentuating',\n",
       " 'accept',\n",
       " 'accepting',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accompanies',\n",
       " 'accompanying',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accumulated',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achilles',\n",
       " 'achingly',\n",
       " 'achival',\n",
       " 'achronological',\n",
       " 'acid',\n",
       " 'acknowledges',\n",
       " 'acolyte',\n",
       " 'acquire',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actorliness',\n",
       " 'actorly',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'adicional',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'adobo',\n",
       " 'adolescent',\n",
       " 'adoration',\n",
       " 'adored',\n",
       " 'adoring',\n",
       " 'adorned',\n",
       " 'adorns',\n",
       " 'adrenaline',\n",
       " 'adrenalized',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'aerial',\n",
       " 'aesthetic',\n",
       " 'affability',\n",
       " 'affair',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionately',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmational',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'affluence',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'agape',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agey',\n",
       " 'aggrandizing',\n",
       " 'aggravating',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aging',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahola',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'airhead',\n",
       " 'airless',\n",
       " 'aisle',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'alain',\n",
       " 'album',\n",
       " 'alcatraz',\n",
       " 'aleck',\n",
       " 'alert',\n",
       " 'alexandre',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloof',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'always',\n",
       " 'amalgam',\n",
       " 'amalgamating',\n",
       " 'amaro',\n",
       " 'amateurish',\n",
       " 'amateurishness',\n",
       " 'amaze',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambience',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'ambrose',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amiable',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amor',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amorous',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'am√©lie',\n",
       " 'ana',\n",
       " 'anachronistic',\n",
       " 'anakin',\n",
       " 'analgesic',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'anarchic',\n",
       " 'anarchist',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andrei',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angelique',\n",
       " 'angels',\n",
       " 'angle',\n",
       " 'angling',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'anomie',\n",
       " 'anonymity',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'ante',\n",
       " 'anthony',\n",
       " 'anthropologically',\n",
       " 'anti',\n",
       " 'antiseptic',\n",
       " 'antler',\n",
       " 'antonia',\n",
       " 'antsy',\n",
       " 'antwone',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'ao',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apenas',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appetizer',\n",
       " 'applaud',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciates',\n",
       " 'appreciative',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'apt',\n",
       " 'apted',\n",
       " 'apuestas',\n",
       " 'aquatic',\n",
       " 'aquel',\n",
       " 'ararat',\n",
       " 'arbitrary',\n",
       " 'arch',\n",
       " 'archibald',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'archival',\n",
       " 'archive',\n",
       " 'ardently',\n",
       " 'arduous',\n",
       " 'are',\n",
       " 'area',\n",
       " 'argentine',\n",
       " 'argento',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'aristocrat',\n",
       " 'aristocratic',\n",
       " 'arithmetic',\n",
       " 'ark',\n",
       " 'arliss',\n",
       " 'arm',\n",
       " 'armenia',\n",
       " 'armenian',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arrangement',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arresting',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'art',\n",
       " 'artefact',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'arts',\n",
       " 'artsy',\n",
       " 'as',\n",
       " 'asay',\n",
       " 'ascension',\n",
       " 'ascertain',\n",
       " 'ash',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspiration',\n",
       " 'aspiring',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assaultive',\n",
       " 'assayas',\n",
       " 'assed',\n",
       " 'assembled',\n",
       " 'assertive',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assimilated',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astounding',\n",
       " 'astray',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'atacar',\n",
       " 'atacarse',\n",
       " 'atavistic',\n",
       " 'athlete',\n",
       " 'athletic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherics',\n",
       " 'atonal',\n",
       " 'atop',\n",
       " 'atreve',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attal',\n",
       " 'attempt',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attuned',\n",
       " 'audacious',\n",
       " 'audacity',\n",
       " 'audiard',\n",
       " 'audience',\n",
       " 'augmentation',\n",
       " 'august',\n",
       " 'auschwitz',\n",
       " 'auspicious',\n",
       " 'aussie',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'austrian',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticate',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'autobiographical',\n",
       " 'autocritique',\n",
       " 'automated',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'avary',\n",
       " 'avenges',\n",
       " 'average',\n",
       " 'aversion',\n",
       " 'avert',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'awake',\n",
       " 'awakens',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'ayala',\n",
       " 'ayurveda',\n",
       " 'babbitt',\n",
       " 'babe',\n",
       " 'baboon',\n",
       " 'baby',\n",
       " 'baca',\n",
       " 'back',\n",
       " 'backdrop',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backseat',\n",
       " 'backstage',\n",
       " 'backstory',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badder',\n",
       " 'badge',\n",
       " 'badly',\n",
       " 'baffled',\n",
       " 'baffling',\n",
       " 'bag',\n",
       " 'bagatelle',\n",
       " 'baio',\n",
       " 'bait',\n",
       " 'baked',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'bale',\n",
       " 'ball',\n",
       " 'ballast',\n",
       " 'ballerina',\n",
       " 'ballet',\n",
       " 'balletic',\n",
       " 'ballistic',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'balm',\n",
       " 'bam',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'banged',\n",
       " 'bar',\n",
       " 'baran',\n",
       " 'barbara',\n",
       " 'barbarism',\n",
       " 'barbera',\n",
       " 'bard',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barker',\n",
       " 'barlow',\n",
       " 'barney',\n",
       " 'barrage',\n",
       " 'barrie',\n",
       " 'barrier',\n",
       " 'barris',\n",
       " 'barry',\n",
       " 'barrymore',\n",
       " 'bartleby',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'bastard',\n",
       " 'bastion',\n",
       " 'bath',\n",
       " 'bathing',\n",
       " 'bathos',\n",
       " 'battista',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'battling',\n",
       " 'bawdy',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beachcombing',\n",
       " 'beacon',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'bearable',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beatnik',\n",
       " 'beatrice',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'beck',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bedroom',\n",
       " 'bedside',\n",
       " 'bedtime',\n",
       " 'bee',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'befits',\n",
       " 'befuddled',\n",
       " 'befuddlement',\n",
       " 'began',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begs',\n",
       " 'beguiling',\n",
       " 'begun',\n",
       " 'behan',\n",
       " 'behaved',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beijing',\n",
       " 'belated',\n",
       " 'belief',\n",
       " 'believability',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'believing',\n",
       " 'bella',\n",
       " 'belly',\n",
       " 'belo',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'belushi',\n",
       " 'ben',\n",
       " 'benchmark',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benign',\n",
       " 'benigni',\n",
       " 'benshan',\n",
       " 'bent',\n",
       " 'bergmanesque',\n",
       " 'berkley',\n",
       " 'berlin',\n",
       " 'bernal',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betrayal',\n",
       " 'bettany',\n",
       " 'better',\n",
       " 'betty',\n",
       " 'bewildered',\n",
       " 'bewilderingly',\n",
       " 'bewitched',\n",
       " 'beyond',\n",
       " 'biased',\n",
       " 'bibi',\n",
       " 'bible',\n",
       " 'bicycle',\n",
       " 'bid',\n",
       " 'bidder',\n",
       " 'bielinsky',\n",
       " 'bien',\n",
       " 'bierbichler',\n",
       " 'big',\n",
       " 'bigelow',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bile',\n",
       " 'bilked',\n",
       " 'bill',\n",
       " 'billy',\n",
       " 'bind',\n",
       " 'binks',\n",
       " 'binoche',\n",
       " 'bio',\n",
       " 'biopic',\n",
       " 'bird',\n",
       " 'birot',\n",
       " 'birthday',\n",
       " 'bisexual',\n",
       " 'bisset',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'biting',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'bittersweet',\n",
       " 'biz',\n",
       " 'bizarre',\n",
       " 'bjarne',\n",
       " 'bjorkness',\n",
       " 'black',\n",
       " 'blade',\n",
       " 'blair',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blandly',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blaring',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'blazing',\n",
       " 'bleak',\n",
       " 'bleakly',\n",
       " 'bled',\n",
       " 'bleibtreu',\n",
       " 'blend',\n",
       " 'blended',\n",
       " 'blender',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'bleu',\n",
       " 'blimey',\n",
       " 'blimp',\n",
       " 'blisteringly',\n",
       " 'blockbuster',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'blooded',\n",
       " 'bloodshed',\n",
       " 'bloodstream',\n",
       " 'bloodsucker',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blowout',\n",
       " 'blue',\n",
       " 'blueprint',\n",
       " 'bluescreen',\n",
       " 'bluff',\n",
       " 'blurry',\n",
       " 'blush',\n",
       " 'bmws',\n",
       " 'bmx',\n",
       " 'board',\n",
       " 'boarder',\n",
       " 'boast',\n",
       " 'boasting',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodice',\n",
       " 'bodied',\n",
       " 'bodily',\n",
       " 'body',\n",
       " 'bog',\n",
       " 'bogdanich',\n",
       " 'bogdanovich',\n",
       " 'bogged',\n",
       " 'bogus',\n",
       " 'boiling',\n",
       " 'boisterous',\n",
       " 'bold',\n",
       " 'bolder',\n",
       " 'boldly',\n",
       " 'bollywood',\n",
       " 'bolstered',\n",
       " 'bomb',\n",
       " 'bombay',\n",
       " 'bombing',\n",
       " 'bona',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'boom',\n",
       " 'boomer',\n",
       " 'boorishness',\n",
       " 'boosted',\n",
       " 'boot',\n",
       " 'booty',\n",
       " 'boozy',\n",
       " 'border',\n",
       " 'bordering',\n",
       " 'borderline',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrowed',\n",
       " 'borstal',\n",
       " 'botched',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothersome',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bouncy',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'boundless',\n",
       " 'bourne',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bowel',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxing',\n",
       " 'boy',\n",
       " 'boyd',\n",
       " 'brady',\n",
       " 'brain',\n",
       " 'brainless',\n",
       " 'branagh',\n",
       " 'brand',\n",
       " 'brash',\n",
       " 'brass',\n",
       " 'brat',\n",
       " 'bratt',\n",
       " 'bratty',\n",
       " 'bravado',\n",
       " 'braveheart',\n",
       " 'bravely',\n",
       " 'bravery',\n",
       " 'bravo',\n",
       " 'bravura',\n",
       " 'brazenly',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breaking',\n",
       " 'breakingly',\n",
       " 'breakthrough',\n",
       " 'breath',\n",
       " 'breathes',\n",
       " 'breathing',\n",
       " 'breathless',\n",
       " 'breathtaking',\n",
       " 'breathtakingly',\n",
       " 'brecht',\n",
       " 'breckin',\n",
       " 'breezy',\n",
       " 'breitbart',\n",
       " 'brendan',\n",
       " 'brew',\n",
       " 'brian',\n",
       " 'bride',\n",
       " 'bridge',\n",
       " 'bridget',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brightly',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brim',\n",
       " 'brimming',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brink',\n",
       " 'brio',\n",
       " 'brisk',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'broad',\n",
       " 'broadside',\n",
       " 'broadway',\n",
       " 'brogue',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brooding',\n",
       " 'brooklyn',\n",
       " 'broomfield',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruce',\n",
       " 'bruising',\n",
       " 'brunt',\n",
       " 'brush',\n",
       " 'brushed',\n",
       " 'brutal',\n",
       " 'brutality',\n",
       " 'brutally',\n",
       " 'bryan',\n",
       " 'bubble',\n",
       " 'bubbly',\n",
       " 'bucket',\n",
       " 'budding',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buff',\n",
       " 'buffeted',\n",
       " 'buffoon',\n",
       " 'buggy',\n",
       " 'bui',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bullet',\n",
       " 'bullfighter',\n",
       " 'bullock',\n",
       " 'bullwinkle',\n",
       " 'bumbling',\n",
       " ...]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(vocab)\n",
    "word_scores = np.zeros((V, 2))\n",
    "for i in range(V):\n",
    "    x_word = np.zeros((1, V))\n",
    "    x_word[:,i] = 1 # only the \"i\" word appeared\n",
    "    word_scores[i] = model.predict_proba(x_word)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44490945, 0.55509055],\n",
       "       [0.63665779, 0.36334221],\n",
       "       [0.48037753, 0.51962247],\n",
       "       ...,\n",
       "       [0.50078706, 0.49921294],\n",
       "       [0.49980275, 0.50019725],\n",
       "       [0.57915321, 0.42084679]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8541"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_neg = np.sort(word_scores.view('float64,float64'), order=['f1'], axis=0)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.8560070368633268, 0.1439929631366732)],\n",
       " [(0.8385242792610248, 0.1614757207389752)],\n",
       " [(0.8362318540583138, 0.16376814594168615)],\n",
       " [(0.8334846032745392, 0.1665153967254608)],\n",
       " [(0.8328677501230323, 0.1671322498769677)]]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_neg.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_pos = np.sort(word_scores.view('float64,float64'), order=['f0'], axis=0)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.1821982733787374, 0.8178017266212626)],\n",
       " [(0.23727185614495638, 0.7627281438550436)],\n",
       " [(0.23791880136993304, 0.762081198630067)],\n",
       " [(0.24410715666922478, 0.7558928433307752)],\n",
       " [(0.24675746897918704, 0.753242531020813)]]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_pos.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1334"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_scores.tolist().index([0.8560070368633268, 0.1439929631366732])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "neg_words = []\n",
    "\n",
    "for values in five_pos.tolist():\n",
    "    ind = word_scores.tolist().index(list(values[0]))\n",
    "    pos_words.append(vocab[ind])\n",
    "    \n",
    "for values in five_neg.tolist():\n",
    "    ind = word_scores.tolist().index(list(values[0]))\n",
    "    neg_words.append(vocab[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world', 'solid', 'heart', 'rare', 'moving']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cliche', 'worst', 'dull', 'bad', 'boring']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index(\"awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38742827, 0.61257173])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_scores[585]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ambos casos se opt√≥ por obtener el top 5 y tanto en las palabras positivas como negativas obtenidas se observa que a nivel sem√°ntico no parecen palabras con una intensidad muy grande en sus respectivos sentimiento, por ejemplo la palabra \"world\" que viene siendo la mas positiva dentro de su conjunto, no es una palabra que denote mucho positivismo si se compara con \"good\", \"beautiful\" o \"awesome\". Esto da para pensar que de forma individual el modelo de regresion logistica con parametro de regularizacion C=1.0 puede no ser adecuado para realizar el trabajo, aun cuando al analizar frases tenga el mejor desempe√±o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n)<a class=\"anchor\" id=\"n\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming en vez de Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def base_word(word):\n",
    "    wordstemmer = PorterStemmer()\n",
    "    return wordstemmer.stem(word)\n",
    "def word_extractor(text):\n",
    "    wordstemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #delete stopwords\n",
    "            words+=\" \"+word\n",
    "        \n",
    "    return words\n",
    "... #try yourself\n",
    "word_extractor(\"I love to eat cake\")\n",
    "word_extractor(\"I love eating cake\")\n",
    "word_extractor(\"I loved eating the cake\")\n",
    "word_extractor(\"I do not love eating cake\")\n",
    "word_extractor(\"I don't love eating cake\")\n",
    "... #try yourself\n",
    "texts_train = [word_extractor(text[1]) for text in df_train_text.to_numpy()]\n",
    "texts_val = [word_extractor(text[1]) for text in df_val_text.to_numpy()]\n",
    "texts_test = [word_extractor(text[1]) for text in df_test.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary=False) #TF representation\n",
    "vectorizer.fit(texts_train)\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "... #transform val and test\n",
    "\n",
    "\n",
    "vectorizer2 = CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer2.fit(texts_val)\n",
    "features_val = vectorizer.transform(texts_val)\n",
    "\n",
    "vectorizer3 = CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer3.fit(texts_test)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "vocab2 = vectorizer.get_feature_names()\n",
    "dist2=list(np.array(features_val.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "vocab3 = vectorizer.get_feature_names()\n",
    "dist3=list(np.array(features_test.sum(axis=0)).reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model, train_acc, test_acc = do_LOGIT(features_train,labels_train,features_val,labels_val, param= 1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7259425998874508"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, al realizar el proceso de Stemming se consigue un accuracy mayor en el test set en el regresor logistico con parametro de regularizacion C= 1.0. El aumento es de un 1% respecto al obtenido en el apartado [k](#k). Esto resulta curioso considerando que lemmatization considera el contexto a la hora de realizar la reduccion a la raiz, mientras que stemming lo realiza considerando las palabras de forma individual, por lo que se pensar√≠a inicialmente que utilizando el primero se obtendrian mejores resultados. Ahora el uso de stemming produce que al reducir una palabra en contextos diferentes se obtenga el mismo resultado, disminuyendo asi la cantidad de palabras que el TF consideraria, pudiendo ser esta la causa de un mejor desempe√±o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o)<a class=\"anchor\" id=\"o\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(binary=False, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, sublinear_tf=False)\n",
    "\n",
    "tfidf_model.fit(texts_train)\n",
    "features_train = tfidf_model.transform(texts_train)\n",
    "\n",
    "#tfidf_model.fit(texts_val)\n",
    "features_val = tfidf_model.transform(texts_val)\n",
    "\n",
    "#tfidf_model.fit(texts_test)\n",
    "features_test = tfidf_model.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param C=  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model, train_acc, test_acc = do_LOGIT(features_train,labels_train,features_val,labels_val, param= 1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9331691874780161"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6947960618846695"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386043894203714"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando TF-IDF se obtienen mejores resultados con el modelo de regresion logistica, aumentando el accuracy nuevamente llegando asi a un 74%. Se testeo cambiando parametros en el vecotirzador para utilizar unigramas y bigramas, y si bien el accuracy en training y en validacion suben, en testing disminuyen, por lo que se decide optar por solo dejar el uso de unigramas. Tambien se probo utilizando solo bigramas, pero el resultado de test set disminuyo por debajo del 60%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p)<a class=\"anchor\" id=\"p\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Analysis Testing Results ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.74      0.74      0.74      1803\n",
      "           +       0.73      0.74      0.73      1751\n",
      "\n",
      "    accuracy                           0.74      3554\n",
      "   macro avg       0.74      0.74      0.74      3554\n",
      "weighted avg       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model, x, y):\n",
    "    print(\"Detailed Analysis Testing Results ...\")\n",
    "    print(classification_report(y, model.predict(x), target_names=['-','+']))\n",
    "score_the_model(model, features_test, labels_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las metricas auxiliares es posible notar que a pesar de que el modelo presenta un buen desempe√±o aun tiene falencias leves a la hora de clasificar muestras en las categorias correctas. Lo que si es destacable es que presenta un rendimiento igual en ambas categorias por lo que no es un problema respecto a que una de ellas tenga mayor importancia que la otra y en ambos casos la cantidad de falsos positivos y falsos negativos no es alta.\n",
    "\n",
    "Ademas, el valor de soporte para ambas clases tambien se aprecia balanceado, por lo que se puede entender que los resultados no se encuentran sesgados debido a dichas cantidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q)<a class=\"anchor\" id=\"q\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Analysis Testing Results ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       0.55      0.99      0.71      1803\n",
      "           +       0.94      0.16      0.28      1751\n",
      "\n",
      "    accuracy                           0.58      3554\n",
      "   macro avg       0.75      0.58      0.49      3554\n",
      "weighted avg       0.74      0.58      0.50      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes_weights = {0: 5, 1: 1} #or choose..\n",
    "model.set_params(class_weight=classes_weights)\n",
    "model.fit(features_train, labels_train)\n",
    "score_the_model(model, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando el cambio de pesos fue posible aumentar el recall del modelo en las etiquetas negativas, lo que se traduce en un aumento en la capacidad que tiene este de acertar a la hora de clasificar los elementos que deberian tener esa etiqueta. Lamentablemente al aumentar el peso de la etiqueta negativa se obtiene una disminucion en el recall de los positivos llegando a ser 0.16 que resulta ser un valor demasiado bajo. Es por los mismo que la precision de la clase positiva sube debido a que al tener mayor importancia el label negativo, es mas dificil que se etiquete como positivo una muestra que es negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r)<a class=\"anchor\" id=\"r\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion continua o categ√≥rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True sent:  0.0 -- Pred sent:  [0.39347299 0.60652701]\n",
      "Raw text:  best described as i know what you did last winter .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.62999398 0.37000602]\n",
      "Raw text:  the script was reportedly rewritten a dozen times -- either 11 times too many or else too few .\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.34377353 0.65622647]\n",
      "Raw text:  . . . a haunting vision , with images that seem more like disturbing hallucinations .\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.44049946 0.55950054]\n",
      "Raw text:  it's not going to be everyone's bag of popcorn , but it definitely gives you something to chew on .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.5010758 0.4989242]\n",
      "Raw text:  there's only one way to kill michael myers for good : stop buying tickets to these movies .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.67497953 0.32502047]\n",
      "Raw text:  a really funny fifteen-minute short stretched beyond its limits to fill an almost feature-length film .\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.45782676 0.54217324]\n",
      "Raw text:  heartwarming here relies less on forced air than on petter n√¶ss' delicate , clever direction . . . and a wonderful , imaginative script by axel hellstenius .\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.53333117 0.46666883]\n",
      "Raw text:  your children will be occupied for 72 minutes .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.49649762 0.50350238]\n",
      "Raw text:  a gob of drivel so sickly sweet , even the eager consumers of moore's pasteurized ditties will retch it up like rancid cr√®me br√ªl√©e .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.69101102 0.30898898]\n",
      "Raw text:  woody , what happened ?\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.62902555 0.37097445]\n",
      "Raw text:  maybe it is formula filmmaking , but there's nothing wrong with that if the film is well-crafted and this one is .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.46761823 0.53238177]\n",
      "Raw text:  britney's performance cannot be faulted . lucy's a dull girl , that's all .\n",
      "\n",
      "True sent:  1.0 -- Pred sent:  [0.4487877 0.5512123]\n",
      "Raw text:  the result is mesmerizing -- filled with menace and squalor .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.73264388 0.26735612]\n",
      "Raw text:  this overlong infomercial , due out on video before month's end , is tepid and tedious .\n",
      "\n",
      "True sent:  0.0 -- Pred sent:  [0.41252236 0.58747764]\n",
      "Raw text:  the overall feel of the film is pretty cheesy , but there's still a real sense that the star trek tradition has been honored as best it can , given the embarrassing script and weak direction .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict_proba(features_test) #or \".predict\"\n",
    "spl = np.random.randint( 0, len(test_pred), size=15)\n",
    "for text, pred_s, true_s in zip(df_test_text[spl], test_pred[spl], labels_test[spl]):\n",
    "    print(\"True sent: \", true_s, \"-- Pred sent: \",pred_s)\n",
    "    print(\"Raw text: \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ventajas de una prediccion continua resultan beneficiosas a la hora de querer estudiar mas clases como lo hce Vader que categoriza en 5 intensidades (muy negativo, negativo, neutro , positivo y muy positivo), mientras que la prediccion categorica resulta util para estudios mas generales respecto a las criticas que en este caso se estudiaron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s)<a class=\"anchor\" id=\"s\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De todos los modelos utilizados a lo largo del desarrollo de la actividad el que presento mejor desempe√±o resulto ser el regresor logistico con un accuracy sobre el 70% seguido por la SVM con kernel linear que tiene un accuracy cercano a 70% pero esta ligeramente por debajo. Teniendo en cuenta que en todos los modelos se realizaron cambios de parametros para ver si se lograba un mejor accuracy, lo mas probable que es que la gran diferenciacion resulte ser la representacion.\n",
    "\n",
    "En lo personal el modelo de Regresion logistica resulta ser uno de los mas comodos de utilizar debido a su bajo tiempo de ejecucion que permite realizar pruebas mas rapidamente y su facil forma de realizar la variacion de parametro al ser uno solo, no como en el caso del arbol de decision que cuenta con el parametro de profundidad y minimo de datos en la muestra para realizar la division en un nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVIDAD 2 <a class=\"anchor\" id=\"Actividad2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./sentiment_polarity/mturk_answers.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Input.id</th>\n",
       "      <th>Input.original_sentence</th>\n",
       "      <th>Input.stemmed_sent</th>\n",
       "      <th>Input.true_sent</th>\n",
       "      <th>Answer.sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>4518</td>\n",
       "      <td>the cast is phenomenal , especially the women .</td>\n",
       "      <td>cast phenomen especi women</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>10415</td>\n",
       "      <td>the metaphors are provocative , but too often ...</td>\n",
       "      <td>metaphor provoc often viewer left puzzl mechan...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>7098</td>\n",
       "      <td>while there's something intrinsically funny ab...</td>\n",
       "      <td>there someth intrins funni sir anthoni hopkin ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>4396</td>\n",
       "      <td>a harrowing account of a psychological breakdo...</td>\n",
       "      <td>harrow account psycholog breakdown</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>2812</td>\n",
       "      <td>. . . a visually seductive , unrepentantly tr...</td>\n",
       "      <td>visual seduct unrepentantli trashi rice instal...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WorkerId  Input.id  \\\n",
       "0  A2HD5XMM48KKJW      4518   \n",
       "1  A2HD5XMM48KKJW     10415   \n",
       "2  A2HD5XMM48KKJW      7098   \n",
       "3  A2HD5XMM48KKJW      4396   \n",
       "4  A2HD5XMM48KKJW      2812   \n",
       "\n",
       "                             Input.original_sentence  \\\n",
       "0   the cast is phenomenal , especially the women .    \n",
       "1  the metaphors are provocative , but too often ...   \n",
       "2  while there's something intrinsically funny ab...   \n",
       "3  a harrowing account of a psychological breakdo...   \n",
       "4   . . . a visually seductive , unrepentantly tr...   \n",
       "\n",
       "                                  Input.stemmed_sent Input.true_sent  \\\n",
       "0                         cast phenomen especi women             pos   \n",
       "1  metaphor provoc often viewer left puzzl mechan...             neg   \n",
       "2  there someth intrins funni sir anthoni hopkin ...             neg   \n",
       "3                 harrow account psycholog breakdown             pos   \n",
       "4  visual seduct unrepentantli trashi rice instal...             pos   \n",
       "\n",
       "  Answer.sent  \n",
       "0         pos  \n",
       "1         neg  \n",
       "2         pos  \n",
       "3         neg  \n",
       "4         pos  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "EMBEDDING_DIM = 300\n",
    "GLOVE_FILE = \"./glove.6B.%dd.txt\"%(EMBEDDING_DIM)\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el mapeo de 'pos' y 'neg' a 1 y 0 respectivamente para luego proceder a calcular los mas votados segun el enfoque (MVhard) expuesto en el paper de Rodrigues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Answer.sent'] == 'pos', 'Answer.sent'] = 1\n",
    "df.loc[df['Answer.sent'] == 'neg', 'Answer.sent'] = 0\n",
    "df.loc[df['Input.true_sent'] == 'pos', 'Input.true_sent'] = 1\n",
    "df.loc[df['Input.true_sent'] == 'neg', 'Input.true_sent'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Input.id</th>\n",
       "      <th>Input.original_sentence</th>\n",
       "      <th>Input.stemmed_sent</th>\n",
       "      <th>Input.true_sent</th>\n",
       "      <th>Answer.sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>4518</td>\n",
       "      <td>the cast is phenomenal , especially the women .</td>\n",
       "      <td>cast phenomen especi women</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>10415</td>\n",
       "      <td>the metaphors are provocative , but too often ...</td>\n",
       "      <td>metaphor provoc often viewer left puzzl mechan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>7098</td>\n",
       "      <td>while there's something intrinsically funny ab...</td>\n",
       "      <td>there someth intrins funni sir anthoni hopkin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>4396</td>\n",
       "      <td>a harrowing account of a psychological breakdo...</td>\n",
       "      <td>harrow account psycholog breakdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A2HD5XMM48KKJW</td>\n",
       "      <td>2812</td>\n",
       "      <td>. . . a visually seductive , unrepentantly tr...</td>\n",
       "      <td>visual seduct unrepentantli trashi rice instal...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WorkerId  Input.id  \\\n",
       "0  A2HD5XMM48KKJW      4518   \n",
       "1  A2HD5XMM48KKJW     10415   \n",
       "2  A2HD5XMM48KKJW      7098   \n",
       "3  A2HD5XMM48KKJW      4396   \n",
       "4  A2HD5XMM48KKJW      2812   \n",
       "\n",
       "                             Input.original_sentence  \\\n",
       "0   the cast is phenomenal , especially the women .    \n",
       "1  the metaphors are provocative , but too often ...   \n",
       "2  while there's something intrinsically funny ab...   \n",
       "3  a harrowing account of a psychological breakdo...   \n",
       "4   . . . a visually seductive , unrepentantly tr...   \n",
       "\n",
       "                                  Input.stemmed_sent  Input.true_sent  \\\n",
       "0                         cast phenomen especi women                1   \n",
       "1  metaphor provoc often viewer left puzzl mechan...                0   \n",
       "2  there someth intrins funni sir anthoni hopkin ...                0   \n",
       "3                 harrow account psycholog breakdown                1   \n",
       "4  visual seduct unrepentantli trashi rice instal...                1   \n",
       "\n",
       "   Answer.sent  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener que fue lo mas votado por las personas en cuanto al sentimiento de cada oracion se procede a agrupar los datos segun Id de la oracion para calcular el promedio de los sentimientos y posteriormente redondearlos. Ademas se procede a cambiar el dataframe por el agrupado debido a que se eliminan columas innecesarias como las de WorkerID y la oracion original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['Input.id', 'Input.stemmed_sent'], as_index = False).mean().round(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego se realiza la separacion entre training set y test set para el entrenamiento del Regresor Logistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, y_train, y_test = train_test_split(df, df[\"Input.true_sent\"], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.id</th>\n",
       "      <th>Input.stemmed_sent</th>\n",
       "      <th>Input.true_sent</th>\n",
       "      <th>Answer.sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>gorgeous elabor continu lord ring trilogi huge...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>effect tepid biopic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>sometim movi fun wasabi good place start</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>steer turn snappi screenplai curl edg clever w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>film worth see talk sing head</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.id                                 Input.stemmed_sent  \\\n",
       "0         2  gorgeous elabor continu lord ring trilogi huge...   \n",
       "1         3                                effect tepid biopic   \n",
       "2         4           sometim movi fun wasabi good place start   \n",
       "3         9  steer turn snappi screenplai curl edg clever w...   \n",
       "4        11                      film worth see talk sing head   \n",
       "\n",
       "   Input.true_sent  Answer.sent  \n",
       "0              1.0          1.0  \n",
       "1              1.0          0.0  \n",
       "2              1.0          1.0  \n",
       "3              1.0          1.0  \n",
       "4              1.0          1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_features(dataset):\n",
    "    lista = []\n",
    "    for sentence in dataset[\"Input.stemmed_sent\"]:\n",
    "        sentence_vector = np.zeros(300)\n",
    "        for word in sentence:\n",
    "            if embeddings_index.get(word) is not None:\n",
    "                sentence_vector = sentence_vector + embeddings_index.get(word)\n",
    "        lista.append(sentence_vector)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset_to_features(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset_to_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=0.25: 0.5256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=0.5: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=1: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=1.05: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=1.25: 0.5272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "for c in [0.25, 0.5, 1, 1.05, 1.25]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(train, y_train)\n",
    "    print (f\"Accuracy C={c}: {accuracy_score(y_test, lr.predict(test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver que los resultados no son buenos (no son mucho mejores que lanzar una moneda) se utilizara el promedio de la suma de los vectores obtenidos de las palabras de las oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_featuresv2(dataset):\n",
    "    lista = []\n",
    "    for sentence in dataset[\"Input.stemmed_sent\"]:\n",
    "        sentence_vector = np.zeros(300)\n",
    "        n_words = 0\n",
    "        for word in sentence.split():\n",
    "            n_words += 1\n",
    "            if embeddings_index.get(word) is not None:\n",
    "                sentence_vector = sentence_vector + embeddings_index.get(word)\n",
    "        #print(sentecen_vector)\n",
    "        sentence_vector = sentence_vector / n_words\n",
    "        #print(sentence_vector)\n",
    "        lista.append(sentence_vector)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset_to_featuresv2(train_set)\n",
    "test = dataset_to_featuresv2(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=0.0001: 0.5632\n",
      "Accuracy C=0.001: 0.64\n",
      "Accuracy C=0.01: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=0.1: 0.7016\n",
      "Accuracy C=1.0: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=10.0: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=100.0: 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=1000.0: 0.6952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in np.power(np.repeat(10., 8),np.arange(-4,4)):\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(train, y_train)\n",
    "    print (f\"Accuracy C={c}: {accuracy_score(y_test, lr.predict(test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa una mejora muy considerable al utilizar el promedio de la suma de vectores de palabras que componen una oraci√≥n. Inicialmente se pensaba que bastaba con utilizar la suma de vectores puesto que una de las dimensiones podia representar la polaridad de las palabras por lo que la suma podria ser suficiente a la hora de entrenar un regresor log√≠stico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los mismos valores que en la Actividad 1 es posible apreciar que con parametros de regularizacion C muy bajos se obtienen malos resultados mientras que el peak de desempe√±o se obtiene con un C=0.1 hasta C = 10 tendiendo a disminuir ligeramente con valores mas grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
